{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel computing in Julia\n",
    "In this notebook it is shown how parallel computation can speed up complex computations\n",
    "\n",
    "For this example, `QuadGK`, `Distributed`, `BenchmarkTools` and `SharedArrays` are required, if not already installed please run the following code:\n",
    "\n",
    "```julia\n",
    "using Pkg\n",
    "Pkg.add(\"QuadGK\")\n",
    "Pkg.add(\"Distributed\")\n",
    "Pkg.add(\"BenchmarkTools\")\n",
    "Pkg.add(\"SharedArrays\")\n",
    "``` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5]"
     ]
    }
   ],
   "source": [
    "using Distributed\n",
    "using BenchmarkTools\n",
    "\n",
    "CPUcores=4\n",
    "\n",
    "addprocs(CPUcores) # One should add n workers, where n is the number of available CPU cores\n",
    "print(workers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now need to load the library required for computing the integral (`QuadGK`) and the lib for `SharedArray`s.\n",
    "Since every process need to be able to calculate integrals and operate on arrays, I load the libraies `@everywhere`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using QuadGK\n",
    "@everywhere using SharedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Euler $\\Gamma$ function:\n",
    "$$\\Gamma(z)=\\int_{0}^{\\infty} x^{z-1}e^{-x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere Γ(z)=quadgk(x->x^(z-1)*exp(-x),0,Inf32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now create 2 ```SharedArray```s. Such arrays can be accessed and modified by multiple processes simultaneously and in efficient fashion. They behave like regular arrays if no multiprocessing is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npoints=10000\n",
    "z = SharedArray(rand(range(1,stop=30, length=10000), npoints));\n",
    "a = SharedArray(zeros(npoints)); # results array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function used to fill `a` whith zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reset_a! (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reset_a!()\n",
    "    @distributed for i=1:10000\n",
    "        global a[i]=0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define two functions that will compute $\\Gamma(z)$ at n points between 1:30 (up to 10000 points). The first one is parallelized, the second one not\n",
    "\n",
    "<span style=\"color:red\">Caution:</span> @synch is needed for the benchmark but usually it is not. \n",
    "Tasks can by run asynchronously or synchronously. <br>\n",
    "A synchronous routine waits for all the tasks to finish before returning a results, while an asynchronous computation returns instantaneously a `Future` object, which will contains the results of the computation once it is done. <br>\n",
    "Thus, in order to know the total compute time, it is preferable to run a synchronous task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_me (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_me_distributed(n)\n",
    "    @sync @distributed for i=1:n\n",
    "        global a[i]=Γ(z[i])[1]\n",
    "    end\n",
    "end\n",
    "\n",
    "function test_me_distributed_async(n) #an asynchronous taks to show the results of an asynchronous computation\n",
    "    @distributed for i=1:n\n",
    "        global a[i]=Γ(z[i])[1]\n",
    "    end\n",
    "end\n",
    "\n",
    "function test_me(n)\n",
    "    for i=1:n\n",
    "        global a[i]=Γ(z[i])[1]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.033074 seconds (15.39 k allocations: 831.626 KiB)\n",
      "  3.739367 seconds (197.61 k allocations: 9.708 MiB, 0.16% gc time)\n",
      "  2.994496 seconds (33.94 M allocations: 712.996 MiB, 3.60% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time test_me_distributed_async(10000)\n",
    "@time test_me_distributed(10000)\n",
    "@time test_me(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, an async task requires virually no time, but the computation is still running when a future result is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time with parallelism: 0.28937014896999996 seconds"
     ]
    }
   ],
   "source": [
    "res1=0.\n",
    "n=100\n",
    "reset_a!()\n",
    "for i=1:n\n",
    "    tmp=@timed test_me_distributed(10000)\n",
    "    global res1+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time with parallelism: $(res1/n) seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time single process: 0.8324613159400001 seconds"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "res2=0.\n",
    "reset_a!()\n",
    "n=100\n",
    "for i=1:n\n",
    "    tmp=@timed test_me(10000)\n",
    "    global res2+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time single process: $(res2/n) seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed-up factor: 2.8768043936221783"
     ]
    }
   ],
   "source": [
    "print(\"speed-up factor: $(res2/res1)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
