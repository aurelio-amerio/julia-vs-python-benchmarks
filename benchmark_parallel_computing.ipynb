{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel computing in Julia\n",
    "In this notebook it is shown how parallel computation can speed up complex computations\n",
    "\n",
    "For this example, `QuadGK`, `Distributed`, `BenchmarkTools`, `SharedArrays` and `PyCall` are required, if not already installed please run the following code:\n",
    "\n",
    "```julia\n",
    "using Pkg\n",
    "Pkg.add(\"QuadGK\")\n",
    "Pkg.add(\"Distributed\")\n",
    "Pkg.add(\"BenchmarkTools\")\n",
    "Pkg.add(\"SharedArrays\")\n",
    "Pkg.add(\"PyCall\")\n",
    "\n",
    "using Conda\n",
    "Conda.install(\"scipy\")\n",
    "\n",
    "``` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5]"
     ]
    }
   ],
   "source": [
    "using Distributed\n",
    "using BenchmarkTools\n",
    "\n",
    "CPUcores=4\n",
    "\n",
    "addprocs(CPUcores) # One should add n workers, where n is the number of available CPU cores\n",
    "print(workers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now need to load the library required for computing the integral (`QuadGK`) and the lib for `SharedArray`s.\n",
    "Since every process need to be able to calculate integrals and operate on arrays, I load the libraies `@everywhere`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using QuadGK\n",
    "@everywhere using SharedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Euler $\\Gamma$ function:\n",
    "$$\\Gamma(z)=\\int_{0}^{\\infty} x^{z-1}e^{-x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere Γ(z)=quadgk(x->x^(z-1)*exp(-x),0,Inf32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now create 2 ```SharedArray```s. Such arrays can be accessed and modified by multiple processes simultaneously and in efficient fashion. They behave like regular arrays if no multiprocessing is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npoints=10000\n",
    "z = SharedArray(rand(range(1,stop=30, length=10000), npoints));\n",
    "a = SharedArray(zeros(npoints)); # results array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function used to fill `a` whith zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reset_a! (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reset_a!()\n",
    "    @distributed for i=1:10000\n",
    "        global a[i]=0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define two functions that will compute $\\Gamma(z)$ at n points between 1:30 (up to 10000 points). The first one is parallelized, the second one not\n",
    "\n",
    "<span style=\"color:red\">Caution:</span> @synch is needed for the benchmark but usually it is not. \n",
    "Tasks can by run asynchronously or synchronously. <br>\n",
    "A synchronous routine waits for all the tasks to finish before returning a results, while an asynchronous computation returns instantaneously a `Future` object, which will contains the results of the computation once it is done. <br>\n",
    "Thus, in order to know the total compute time, it is preferable to run a synchronous task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test_me_distributed(n)\n",
    "    @sync @distributed for i=1:n\n",
    "        global a[i]=Γ(z[i])[1]\n",
    "    end\n",
    "end\n",
    "test_me_distributed(3) #run it once so that it is already compiled\n",
    "\n",
    "function test_me_distributed_async(n) #an asynchronous taks to show the results of an asynchronous computation\n",
    "    @distributed for i=1:n\n",
    "        global a[i]=Γ(z[i])[1]\n",
    "    end\n",
    "end\n",
    "test_me_distributed_async(3)\n",
    "\n",
    "function test_me(n)\n",
    "    for i=1:n\n",
    "        global a[i]=Γ(z[i])[1]\n",
    "    end\n",
    "end\n",
    "test_me(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000075 seconds (6 allocations: 928 bytes)\n",
      "  2.685231 seconds (1.33 k allocations: 74.516 KiB)\n",
      "  0.853919 seconds (28.22 M allocations: 440.353 MiB, 2.93% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time test_me_distributed_async(10000)\n",
    "@time test_me_distributed(10000)\n",
    "@time test_me(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, an async task requires virually no time, but the computation is still running when a future result is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time with parallelism: 0.25808894303999996 seconds"
     ]
    }
   ],
   "source": [
    "res1=0.\n",
    "n=100\n",
    "reset_a!()\n",
    "for i=1:n\n",
    "    tmp=@timed test_me_distributed(10000)\n",
    "    global res1+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time with parallelism: $(res1/n) seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time single process: 0.8483086369600007 seconds"
     ]
    }
   ],
   "source": [
    "res2=0.\n",
    "reset_a!()\n",
    "n=100\n",
    "for i=1:n\n",
    "    tmp=@timed test_me(10000)\n",
    "    global res2+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time single process: $(res2/n) seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed-up factor: 3.2868848505010355"
     ]
    }
   ],
   "source": [
    "print(\"speed-up factor: $(res2/res1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, gamma(30) computed using quad in python, without optimization, requires ~410 $\\mu s$, thus the whole test algorithm would require ~4s vs the julia 0.25s $\\rightarrow$ 16x speedup. <br>\n",
    "Now we will use the built-in scipy gamma function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <ufunc 'gamma'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Γ_py=pyimport(\"scipy.special\").gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.692003 seconds (1.42 M allocations: 72.234 MiB, 3.23% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000-element Array{Float64,1}:\n",
       "     1.2947359264256622e11\n",
       "     3.2509308597513952e28\n",
       "     0.924832458065631    \n",
       "     4.1144441290405286e27\n",
       "     6.500379348827447e9  \n",
       "     4.2380409692267726e30\n",
       "     4.905255534140806e24 \n",
       "     1.2184097593626467e12\n",
       "     1.410557008744064e11 \n",
       "     1.3641668103462832e13\n",
       "     1.0549529318242151e7 \n",
       " 54945.54611094829        \n",
       "     9.302839472887822e11 \n",
       "     ⋮                    \n",
       "     4.720226478792006e30 \n",
       "     2.4536512621674158e27\n",
       "     1.2957239287891263e20\n",
       "     6.83193702121948e11  \n",
       "     1.8941324203409977   \n",
       "  5615.012472532945       \n",
       "     6.881516491329566e25 \n",
       "     7.232864198494877e29 \n",
       "     1.4306561093697086   \n",
       "     5.4347603515598996e25\n",
       "   140.72170002594996     \n",
       "     1.7244219195373504e9 "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time Γ_py(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test_me_py()\n",
    "    a=SharedArray(Γ_py(z))\n",
    "end\n",
    "test_me_py();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.006793 seconds (503 allocations: 96.094 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000-element SharedArray{Float64,1}:\n",
       "     1.2947359264256622e11\n",
       "     3.2509308597513952e28\n",
       "     0.924832458065631    \n",
       "     4.1144441290405286e27\n",
       "     6.500379348827447e9  \n",
       "     4.2380409692267726e30\n",
       "     4.905255534140806e24 \n",
       "     1.2184097593626467e12\n",
       "     1.410557008744064e11 \n",
       "     1.3641668103462832e13\n",
       "     1.0549529318242151e7 \n",
       " 54945.54611094829        \n",
       "     9.302839472887822e11 \n",
       "     ⋮                    \n",
       "     4.720226478792006e30 \n",
       "     2.4536512621674158e27\n",
       "     1.2957239287891263e20\n",
       "     6.83193702121948e11  \n",
       "     1.8941324203409977   \n",
       "  5615.012472532945       \n",
       "     6.881516491329566e25 \n",
       "     7.232864198494877e29 \n",
       "     1.4306561093697086   \n",
       "     5.4347603515598996e25\n",
       "   140.72170002594996     \n",
       "     1.7244219195373504e9 "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time test_me_py()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time python: 0.0008779030970000002 seconds"
     ]
    }
   ],
   "source": [
    "res3=0.\n",
    "reset_a!()\n",
    "n3=1000\n",
    "for i=1:n\n",
    "    tmp=@timed test_me_py()\n",
    "    global res3+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time python: $(res3/n3) seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed-up factor python-julia handwritten: 293.9834065080191"
     ]
    }
   ],
   "source": [
    "print(\"speed-up factor python-julia handwritten: $(res1/res3*(n3/n))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so fast, unfortunately. Let's try the native Julia implementation of the gamma function (which is based on the GNU MPFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Native gamma function parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using SpecialFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_me_builtin (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_me_distributed_builtin(n)\n",
    "    @sync @distributed for i=1:n\n",
    "        global a[i]=gamma(z[i])\n",
    "    end\n",
    "end\n",
    "\n",
    "function test_me_builtin(n)\n",
    "    for i=1:n\n",
    "        global a[i]=gamma(z[i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.387159 seconds (438.21 k allocations: 21.647 MiB, 2.90% gc time)\n",
      "  0.012825 seconds (13.96 k allocations: 732.814 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time test_me_distributed_builtin(10)\n",
    "@time test_me_builtin(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time builtin gamma: 0.000198029904 seconds\n",
      "elapsed time builtin gamma: 1.9630980000000007e-6 seconds"
     ]
    }
   ],
   "source": [
    "res4=0.\n",
    "reset_a!()\n",
    "n4=1000\n",
    "for i=1:n\n",
    "    tmp=@timed test_me_distributed_builtin(n)\n",
    "    global res4+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time builtin gamma: $(res4/n4) seconds\\n\")\n",
    "\n",
    "res5=0.\n",
    "reset_a!()\n",
    "n5=1000\n",
    "for i=1:n\n",
    "    tmp=@timed test_me_builtin(n)\n",
    "    global res5+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time builtin gamma: $(res5/n5) seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed-up factor native-hand written: 131470.2287099268 \n",
      "speed-up factor 4-5: 100.87621911896397 \n",
      "speed-up factor native-python: 447.2028890050318"
     ]
    }
   ],
   "source": [
    "print(\"speed-up factor native-hand written: $(res1/res5*(n5/n)) \\n\")\n",
    "print(\"speed-up factor 4-5: $(res4/res5) \\n\")\n",
    "print(\"speed-up factor native-python: $(res3/res5*(n5/n3))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we observe, in this case there is no gain in parallelizing the gamma function. Since it is already really fast, the overhead generated by the parallelization tecnique is higher than the speed gain. \n",
    "Furthermore, an efficient algorithm is much better than the parallelization, leading to a performance increase of $10^5$. <br> \n",
    "As a side note, Julia is **100x faster than python** at computing the gamma function, when properly optimized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
