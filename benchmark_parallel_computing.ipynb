{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel computing in Julia\n",
    "In this notebook it is shown how parallel computation can speed up complex computations\n",
    "\n",
    "For this example, `QuadGK`, `Distributed`, `BenchmarkTools`, `SharedArrays` and `PyCall` are required, if not already installed please run the following code:\n",
    "\n",
    "```julia\n",
    "using Pkg\n",
    "Pkg.add(\"QuadGK\")\n",
    "Pkg.add(\"Distributed\")\n",
    "Pkg.add(\"BenchmarkTools\")\n",
    "Pkg.add(\"SharedArrays\")\n",
    "Pkg.add(\"PyCall\")\n",
    "\n",
    "using Conda\n",
    "Conda.install(\"scipy\")\n",
    "\n",
    "``` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5]"
     ]
    }
   ],
   "source": [
    "using Distributed\n",
    "using BenchmarkTools\n",
    "\n",
    "CPUcores=4\n",
    "\n",
    "addprocs(CPUcores) # One should add n workers, where n is the number of available CPU cores\n",
    "print(workers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now need to load the library required for computing the integral (`QuadGK`) and the lib for `SharedArray`s.\n",
    "Since every process need to be able to calculate integrals and operate on arrays, I load the libraies `@everywhere`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using QuadGK\n",
    "@everywhere using SharedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Euler $\\Gamma$ function:\n",
    "$$\\Gamma(z)=\\int_{0}^{\\infty} x^{z-1}e^{-x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere Γ(z)=quadgk(x->x^(z-1)*exp(-x),0,Inf32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now create 2 ```SharedArray```s. Such arrays can be accessed and modified by multiple processes simultaneously and in efficient fashion. They behave like regular arrays if no multiprocessing is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npoints=10000\n",
    "z = SharedArray(rand(range(1,stop=30, length=10000), npoints));\n",
    "a = SharedArray(zeros(npoints)); # results array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function used to fill `a` whith zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reset_a! (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reset_a!()\n",
    "    @distributed for i=1:10000\n",
    "        global a[i]=0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define two functions that will compute $\\Gamma(z)$ at n points between 1:30 (up to 10000 points). The first one is parallelized, the second one not\n",
    "\n",
    "<span style=\"color:red\">Caution:</span> @synch is needed for the benchmark but usually it is not. \n",
    "Tasks can by run asynchronously or synchronously. <br>\n",
    "A synchronous routine waits for all the tasks to finish before returning a results, while an asynchronous computation returns instantaneously a `Future` object, which will contains the results of the computation once it is done. <br>\n",
    "Thus, in order to know the total compute time, it is preferable to run a synchronous task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test_me_distributed(n)\n",
    "    @sync @distributed for i=1:n\n",
    "        global a[i]=Γ(z[i])[1]\n",
    "    end\n",
    "end\n",
    "test_me_distributed(3) #run it once so that it is already compiled\n",
    "\n",
    "function test_me_distributed_async(n) #an asynchronous taks to show the results of an asynchronous computation\n",
    "    @distributed for i=1:n\n",
    "        global a[i]=Γ(z[i])[1]\n",
    "    end\n",
    "end\n",
    "test_me_distributed_async(3)\n",
    "\n",
    "function test_me(n)\n",
    "    for i=1:n\n",
    "        global a[i]=Γ(z[i])[1]\n",
    "    end\n",
    "end\n",
    "test_me(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000004 seconds (6 allocations: 928 bytes)\n",
      "  3.282285 seconds (1.34 k allocations: 67.719 KiB)\n",
      "  0.835946 seconds (28.41 M allocations: 443.341 MiB, 2.59% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time test_me_distributed_async(10000)\n",
    "@time test_me_distributed(10000)\n",
    "@time test_me(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, an async task requires virually no time, but the computation is still running when a future result is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time with parallelism: 0.28786496399999983 seconds"
     ]
    }
   ],
   "source": [
    "res1=0.\n",
    "n=100\n",
    "reset_a!()\n",
    "for i=1:n\n",
    "    tmp=@timed test_me_distributed(10000)\n",
    "    global res1+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time with parallelism: $(res1/n) seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time single process: 0.8849689530099997 seconds"
     ]
    }
   ],
   "source": [
    "res2=0.\n",
    "reset_a!()\n",
    "n=100\n",
    "for i=1:n\n",
    "    tmp=@timed test_me(10000)\n",
    "    global res2+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time single process: $(res2/n) seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed-up factor: 3.074250303729217"
     ]
    }
   ],
   "source": [
    "print(\"speed-up factor: $(res2/res1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <ufunc 'gamma'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Γ_py=pyimport(\"scipy.special\").gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000561 seconds (45 allocations: 80.172 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000-element Array{Float64,1}:\n",
       "      5.036909328561965e26 \n",
       "   5648.053076193347       \n",
       "      3.028500953928122e27 \n",
       "      3.194235778900446e29 \n",
       "  25327.751423357135       \n",
       "      5.6907983535647095e10\n",
       "      3.4658359830564453e12\n",
       "      4.409596721333813e17 \n",
       "     25.05496951827898     \n",
       "      1.5916887852926785e10\n",
       "      2.5094712119866572e16\n",
       "      2.2121236443213978e18\n",
       "      0.9318220733059418   \n",
       "      ⋮                    \n",
       " 480487.93710176414        \n",
       "      6.0623769827002734e13\n",
       "      3.739530876724871e17 \n",
       "     55.22061589162701     \n",
       "      1.056564564481503    \n",
       "      4.0872478261627494e18\n",
       "      3.0427608342061473e29\n",
       "      7.3428861832682675e22\n",
       "      2.655054630559022e6  \n",
       "    189.4591822683282      \n",
       "      1.0007894228409088e10\n",
       "      5.389019146047299e7  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time Γ_py(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test_me_py()\n",
    "    a=SharedArray(Γ_py(z))\n",
    "end\n",
    "test_me_py();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.002760 seconds (498 allocations: 95.938 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000-element SharedArray{Float64,1}:\n",
       "      5.036909328561965e26 \n",
       "   5648.053076193347       \n",
       "      3.028500953928122e27 \n",
       "      3.194235778900446e29 \n",
       "  25327.751423357135       \n",
       "      5.6907983535647095e10\n",
       "      3.4658359830564453e12\n",
       "      4.409596721333813e17 \n",
       "     25.05496951827898     \n",
       "      1.5916887852926785e10\n",
       "      2.5094712119866572e16\n",
       "      2.2121236443213978e18\n",
       "      0.9318220733059418   \n",
       "      ⋮                    \n",
       " 480487.93710176414        \n",
       "      6.0623769827002734e13\n",
       "      3.739530876724871e17 \n",
       "     55.22061589162701     \n",
       "      1.056564564481503    \n",
       "      4.0872478261627494e18\n",
       "      3.0427608342061473e29\n",
       "      7.3428861832682675e22\n",
       "      2.655054630559022e6  \n",
       "    189.4591822683282      \n",
       "      1.0007894228409088e10\n",
       "      5.389019146047299e7  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time test_me_py()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time python: 0.000197734604 seconds"
     ]
    }
   ],
   "source": [
    "res3=0.\n",
    "reset_a!()\n",
    "n3=1000\n",
    "for i=1:n\n",
    "    tmp=@timed test_me_py()\n",
    "    global res3+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time python: $(res3/n3) seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed-up factor python-julia handwritten: 1455.8148051819994"
     ]
    }
   ],
   "source": [
    "print(\"speed-up factor python-julia handwritten: $(res1/res3*(n3/n))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so fast, unfortunately. Let's try the native Julia implementation of the gamma function (which is based on the GNU MPFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Native gamma function parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using SpecialFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_me_builtin (generic function with 1 method)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_me_distributed_builtin(n)\n",
    "    @sync @distributed for i=1:n\n",
    "        global a[i]=gamma(z[i])\n",
    "    end\n",
    "end\n",
    "\n",
    "function test_me_builtin(n)\n",
    "    for i=1:n\n",
    "        global a[i]=gamma(z[i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.095133 seconds (198.49 k allocations: 9.756 MiB)\n",
      "  0.007734 seconds (12.06 k allocations: 638.119 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time test_me_distributed_builtin(10)\n",
    "@time test_me_builtin(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time builtin gamma: 0.00020210450200000002 seconds\n",
      "elapsed time builtin gamma: 1.798797e-6 seconds"
     ]
    }
   ],
   "source": [
    "res4=0.\n",
    "reset_a!()\n",
    "n4=1000\n",
    "for i=1:n\n",
    "    tmp=@timed test_me_distributed_builtin(n)\n",
    "    global res4+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time builtin gamma: $(res4/n4) seconds\\n\")\n",
    "\n",
    "res5=0.\n",
    "reset_a!()\n",
    "n5=1000\n",
    "for i=1:n\n",
    "    tmp=@timed test_me_builtin(n)\n",
    "    global res5+=tmp[2]\n",
    "end\n",
    "print(\"elapsed time builtin gamma: $(res5/n5) seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed-up factor native-hand written: 160031.93467634195 \n",
      "speed-up factor 4-5: 112.35536972765688 \n",
      "speed-up factor native-python: 109.92602500448912"
     ]
    }
   ],
   "source": [
    "print(\"speed-up factor native-hand written: $(res1/res5*(n5/n)) \\n\")\n",
    "print(\"speed-up factor 4-5: $(res4/res5) \\n\")\n",
    "print(\"speed-up factor native-python: $(res3/res5*(n5/n3))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we observe, in this case there is no gain in parallelizing the gamma function. Since it is already really fast, the overhead generated by the parallelization tecnique is higher than the speed gain. \n",
    "Furthermore, an efficient algorithm is much better than the parallelization, leading to a performance increase of $10^5$. <br> \n",
    "As a side note, Julia is **100x faster than python** at computing the gamma function, when properly optimized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
